version: '3'

# This setup uses: a PostgreSQL database, a Django/REST Framework web application, a Celery worker, and a RabbitMQ message broker.

services:
  rabbit:
    hostname: rabbit
    image: rabbitmq:latest
    environment:
      - RABBITMQ_DEFAULT_USER=admin
      - RABBITMQ_DEFAULT_PASS=password
    ports:
      - "5672:5672"
  worker:
    build: .
    command: celery -A recipe_backend worker -l info # Runs the Celery worker in the container, with log-level set to INFO
    depends_on:
      - rabbit
    volumes:
      - .:/code
  db:
    image: postgres:latest
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data   # Default Postgres data directory on Linux
    environment:
      - POSTGRES_USER=lyle
      - POSTGRES_PASSWORD=secret
      - POSTGRES_DB=test_database
    restart: always
  web:
    build: .
    command: bash -c "/code/wait-for-postgres.sh db
             && python /code/manage.py makemigrations && python /code/manage.py migrate
             && python /code/manage.py loaddata ingredients.json recipes.json recipe_ingredient.json
             && python /code/manage.py populate
             && python /code/manage.py runserver 0.0.0.0:8000"
    container_name: "recipes_api"
    volumes:
      - .:/code
    ports:
      - "8000:8000"
    restart: on-failure
    depends_on: # The web service should be launched after the Postgres and RabbitMQ containers are up and running
      - db
      - rabbit
volumes:
  pgdata: